#ifndef HASH_TABLE_HPP
#define HASH_TABLE_HPP

#include <cstddef>
#include <cstdint>
#include <memory>
#include <functional>
#include <type_traits>
#include <vector>
#include <optional>
#include <bit>
#include <cassert>
#include <bitset>
// To-Do: 
/*
1. Testing each Method - likely some inconsistencies in passing by ref/ptr (particularly in insert) 
2. Multithreading/Concurrency applications & guardrails - MAJOR undertaking probably. Let's see if this shit runs first
*/

// FNV-1a Hashing Algorithm with SIMD.
// *** Some SIMD - Integrate with NEON later if you want. ***


[[nodiscard]] inline std::uint64_t hash_key(const void* data, size_t len) noexcept {
    constexpr uint64_t INITIAL = 0xCBF29CE484222325;
    constexpr uint64_t MULTIPLIER = 0x100000001B3;

    uint64_t hash = INITIAL;
    const uint8_t* bytes = static_cast<const uint8_t*>(data);
    size_t i = 0;

    for (; i + 4 <= len; i += 4) { 
        hash = (hash ^ bytes[i]) * MULTIPLIER;
        hash = (hash ^ bytes[i + 1]) * MULTIPLIER;
        hash = (hash ^ bytes[i + 2]) * MULTIPLIER;
        hash = (hash ^ bytes[i + 3]) * MULTIPLIER;
    }

    for (; i < len; i++) {
        hash = (hash ^ bytes[i]) * MULTIPLIER;
    }

    return hash;
}
template <typename K>
[[nodiscard]] inline std::uint64_t hash_key(const K& key) noexcept {
    if constexpr (std::is_integral_v<K>) { 
        return hash_key(reinterpret_cast<const uint8_t*>(&key), sizeof(K));  
    } else if constexpr (std::is_same_v<K, std::string> || std::is_same_v<K, std::string_view>) {
        return hash_key(reinterpret_cast<const uint8_t*>(key.data()), key.size());
    } else if constexpr (std::is_same_v<K, std::vector<uint8_t>>) {
        return hash_key(reinterpret_cast<const uint8_t*>(key.data()), key.size());
    } else {
        static_assert(sizeof(K) == 0, "unsupported key type for hash_key :(.");
    }
}

// Basic RAII - Delete copy-consructors, allow transfer of ownership only.
// Our Node contains its HashCode (generated by FNV-1a) and next_ (pointing to a unique_ptr).

template<typename K, typename V>
class HNode {
public:
    HNode(K key, V value, uint64_t hash) : key_(std::move(key)), value_(std::move(value)), hcode_(hash) {}

    HNode() = delete; 
    ~HNode() = default; 
    
    HNode(const HNode&) = delete; 
    HNode& operator=(const HNode&) = delete; 
    
    HNode(HNode&&) noexcept = default; 
    HNode& operator=(HNode&&) noexcept = default; 

    K key_;
    V value_;
    std::uint64_t hcode_;
    std::unique_ptr<HNode<K, V>> next_;
};

template<typename K, typename V>
class HTable {
public:
    // Constructor to roof initial_size to the nearest exponent of 2 and call initialize. (in private)
    explicit HTable(size_t initial_size = 0) {
        if (initial_size > 0) {
            initialize(std::bit_ceil(initial_size));
        }
    }
    // RAII - Delete Copy Construction & Allow ownership transfer of unique_pointer nodes
    HTable(const HTable&) = delete; 
    HTable& operator=(const HTable&) = delete; 

    HTable(HTable&&) noexcept = default; 
    HTable& operator=(HTable&&) noexcept = default; 

    // Insert function with safety check (initialize on k_min_cap of 4 if empty) and move semantics.
    void insert(K key, V value) {
        if (buckets_.empty()) {
            initialize(k_min_cap);
        }
    
        uint64_t hash = hash_key(key);  // FIXED: Use correct `hash_key` function
        size_t pos = hash & mask_;
    
        auto node = std::make_unique<HNode<K, V>>(std::move(key), std::move(value), hash);
        node->next_ = std::move(buckets_[pos]);          
        buckets_[pos] = std::move(node);
        size_++;
    }
    

    HNode<K, V>* lookup(const K& key) {
        if (buckets_.empty()) {
            return nullptr;
        }
    
        uint64_t hash = hash_key(key);
        size_t pos = hash & mask_;
        HNode<K, V>* current = buckets_[pos].get();
    
        while (current) {
            if (current->key_ == key) {
                return current;  // FIXED: Return full node, not just value
            }
            current = current->next_.get();
        }
        return nullptr;
    }
    

    // Accept anonymous comparator function and key, given the mask_ and position, get index current with raw ptr
    // and iterate until comparator is true, we return the unique_pointer after rechaining (avoid dangling ptrs).
    std::optional<V> remove(const K& key) {
        if (buckets_.empty()) {
            return std::nullopt;
        }
    
        uint64_t hash = hash_key(key);
        size_t pos = hash & mask_;
        HNode<K, V>* current = buckets_[pos].get();
        HNode<K, V>* prev = nullptr;
    
        while (current) {
            if (current->key_ == key) {
                std::optional<V> value = std::move(current->value_);
    
                if (prev) {
                    prev->next_ = std::move(current->next_);
                } else {
                    buckets_[pos] = std::move(current->next_);
                }
    
                size_--;
                return value;
            }
            prev = current;
            current = current->next_.get();
        }
        return std::nullopt;
    }

    std::unique_ptr<HNode<K, V>> steal_first_node(size_t& pos) {
        while (pos < buckets_.size() && !buckets_[pos]) {
            pos++; 
        }
    
        if (pos >= buckets_.size()) {
            return nullptr;
        }
    
        auto node = std::move(buckets_[pos]);
        buckets_[pos] = std::move(node->next_);
        size_--;
        return node;
    }
    
    [[nodiscard]] size_t size() const noexcept { return size_; } 
    [[nodiscard]] size_t capacity() const noexcept { return mask_ + 1; } 
    bool empty() const noexcept { return size_ == 0; } 

    void clear() {
        buckets_.clear();  
        size_ = 0;
        mask_ = 0;
    }
    
private:
    std::vector<std::unique_ptr<HNode<K,V>>> buckets_; 
    size_t mask_{0}; 
    size_t size_{0}; 

    static constexpr size_t k_min_cap = 4;

    // Helper function for our constructor, 
    // A. Check if capacity is exponent of 2, if true, continue
    // B. Ensure capacity is at least 4, and resize it
    // C. Initilize mask_ as capacity - 1 (bitmasking operation for XOR replacement) and init size_ to 0. 
    void initialize(size_t capacity) { 
        assert(std::has_single_bit(capacity));  
        capacity = std::max(capacity, k_min_cap); 
        
        buckets_.resize(capacity);
        mask_ = capacity - 1; 
        size_ = 0; 
    }
};

template<typename K, typename V>
class HMap {
public:
    HMap() = default;
    ~HMap() = default;

    // RAII - Delete Copy Construction & Allow ownership transfer of unique_pointer nodes
    HMap(const HMap&) = delete; 
    HMap& operator=(const HMap&) = delete; 

    HMap(HMap&& other) noexcept
    : primary_table_(std::move(other.primary_table_)),
      temporary_table_(std::move(other.temporary_table_)),
      resizing_pos_(other.resizing_pos_) {}

    HMap& operator=(HMap&& other) noexcept {
        if (this != &other) {
            primary_table_ = std::move(other.primary_table_);
            temporary_table_ = std::move(other.temporary_table_);
            resizing_pos_ = other.resizing_pos_;
        }
        return *this;
    }

    // If our primary HTable is empty, we 
    void insert(K key, V value) { 
        // Initialize our primary_table to k_min_cap if empty. Ensuring capacity is at least 4. 
        if (primary_table_.empty()) { 
            primary_table_ = HTable<K, V>(k_min_cap);
        }
        uint64_t hash = hash_key(key);
        // uint64_t hash = hash_key(key);
        // auto node = std::make_unique<HNode<K, V>>(std::move(key), std::move(value), hash);
        // primary_table_.insert(std::move(key), std::move(value));  // FIXED: Pass both arguments
        primary_table_.insert(key, value);  // FIXED: Pass key and value directly

        // Here, we want to check if a resizing_table operation is taking place. If true, we skip starting a new resize operation.
        if (!temporary_table_) {  // We calculate our load factor here as size/capacity 
            size_t load_factor = primary_table_.size() / primary_table_.capacity();
            if (load_factor >= k_max_load_factor) { //If our ratio exceeds our maximum tolerable load factor, then we commence a resize op.
                start_resize();
            }
        }
        help_resize(); // On every function call we'll find this method - it essentially offloads 15 items from our primary_table object
    }
    
    // Pass in a key and comparator function. We call help_resize before to ensure our node isn't lost after the 15 swaps!
    V* find(const K& key) {
        help_resize();
    
        if (auto* node = primary_table_.lookup(key)) {
            return &(node->value_);
        }
    
        if (temporary_table_) {
            if (auto* node = temporary_table_->lookup(key)) {
                return &(node->value_);
            }
        }
    
        return nullptr;
    }

    // Once again, similar to find - We pass in a key and comparator function, and we call help_resize. We should call it earlier here as 
    // this improves our performance as keys are migrated to primary_DB, this increases our chances of finding the key in the first check.
    std::optional<V> remove(const K& key) {
        help_resize();
    
        if (auto node = primary_table_.remove(key)) {  // node is `std::optional<V>`
            return node;  // FIXED: return `std::optional<V>` directly
        }
    
        if (temporary_table_) {
            if (auto node = temporary_table_->remove(key)) {
                return node;  // FIXED
            }
        }
    
        return std::nullopt;
    }
    
    
    
    std::unique_ptr<HNode<K, V>> steal_first_node(size_t& pos) {
    if (!temporary_table_) {
        return nullptr;
    }
    return temporary_table_->steal_first_node(pos);
}

    
    [[nodiscard]] size_t size() const noexcept {
        return primary_table_.size() + 
               (temporary_table_ ? temporary_table_->size() : 0); // Get the size of both primary and resizing table (if exists).
    }
    
    bool empty() const noexcept { return size() == 0; } // method for checking if the above size()==0, for convenience.
    
    void clear() {
        primary_table_.clear();  // Clear primary hash table
        temporary_table_.reset();  // Remove temporary table if resizing
        resizing_pos_ = 0;  // Reset migration position
    }
    
private:
    static constexpr size_t max_work = 15; // 15 transfers per help_resize call 
    static constexpr size_t k_max_load_factor = 8; // Max Average of 8 nodes per bucket before start_resize is called!
    static constexpr size_t k_min_cap = 4; // If constructor is called we want the minimum capacity to be 4 buckets!

    HTable<K,V> primary_table_;
    std::optional<HTable<K,V>> temporary_table_;
    size_t resizing_pos_{0};

    void help_resize() {
        // Sanity check! Do not proceed if resizing table does not exist
        if (!temporary_table_) {
            return;
        }
        // we set work_done to be 15 meaning - if work_done > 15, or there are no more nodes to process we exit the loop
        // If w
        size_t work_done = 0;
        while (work_done < max_work && !temporary_table_->empty()) {
            // 'defensive programming' but probably unnecessary as we only increment when moving through empty buckets.
            // Will leave it as it wont cause problems... probably
            if (resizing_pos_ >= temporary_table_->capacity()) {
                resizing_pos_ = 0;
            }

            // current bucket to process is indicating by resizing_pos_
            auto node = temporary_table_->steal_first_node(resizing_pos_);
            if (node) {
                primary_table_.insert(std::move(node->key_), std::move(node->value_));
            }
        }

        if (temporary_table_->empty()) { // If empty, we reset resizing_table (all buckets) and reinit resizing_pos to 0. Once LOAD FACTOR / CAPACITY > 8 it'll hold primary_table contents again via enplace node transfers.
            temporary_table_.reset();
            resizing_pos_ = 0;
        }
    }
    void start_resize() {
        assert(!temporary_table_); //  first a sanity check that resizing table doesn't already exist!
        size_t new_capacity = primary_table_.capacity() * 2; // new_capacity will be 2x previous, this is fairly standard.
        temporary_table_.emplace(std::move(primary_table_)); // Mark primary_table as an rvalue, and then transfer the contents emplace to resizing_table
        primary_table_ = HTable<K,V>(new_capacity); // Create a new primary_table with the new doubled capacity 
        resizing_pos_ = 0; // Pointer indicating which bucket we're putting into primary
    }
};

#endif // HASH_TABLE_HPP